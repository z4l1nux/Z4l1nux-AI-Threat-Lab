# Configurações do Ollama (para modelos locais)
OLLAMA_BASE_URL=http://my-ollama-ip-server:11434
MODEL_OLLAMA=phi4-mini:latest
EMBEDDING_MODEL=nomic-embed-text:latest

# Configurações do OpenRouter (para modelos remotos)
OPENROUTER_API_KEY=sk-or-my-apkey
MODEL_OPENROUTER=meta-llama/llama-3.3-70b-instruct:free

# Gemini Configuration (Google - Opcional)
GEMINI_API_KEY=AI-my-gemini-api-key
MODEL_GEMINI=gemini-2.5-flash
EMBEDDING_MODEL_GEMINI=text-embedding-004

# Configurações do Neo4j
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=choose-your-password

# Configurações do servidor backend
BACKEND_PORT=3001
FRONTEND_URL=http://localhost:5173

# Configurações de cache
RESPONSE_CACHE_TTL_MS=300000
RETRIEVAL_CACHE_TTL_MS=300000

# Modo de busca
SEARCH_MODE=neo4j

# Configurações de upload
MAX_FILE_SIZE=10485760
ALLOWED_EXTENSIONS=pdf,docx,doc,txt,md,xml,json,csv
OLLAMA_TIMEOUT=180000

# ===========================================
OLLAMA_TIMEOUT=180000
OLLAMA_MAX_RETRIES=2

# Contexto padrão para todos os modelos (8k tokens)
OLLAMA_DEFAULT_CONTEXT_SIZE=8192

# Configurações específicas por modelo (baseado nos seus modelos disponíveis)
# Modelos leves - contexto maior
OLLAMA_CONTEXT_MISTRAL_LATEST=8192
OLLAMA_CONTEXT_LLAMA3_1_LATEST=8192
OLLAMA_CONTEXT_PHI4_MINI_LATEST=16384
OLLAMA_CONTEXT_GRANITE3_3_8B=8192

# Modelos médios - contexto moderado
OLLAMA_CONTEXT_QWEN2_5_CODER_7B=6144
OLLAMA_CONTEXT_QWEN3_8B=6144
OLLAMA_CONTEXT_DEEPSEEK_R1_LATEST=6144
OLLAMA_CONTEXT_WHITERABBITNEO_2_5_QWEN_2_5_CODER_7B_LATEST=6144

# Compressão automática
OLLAMA_AUTO_COMPRESS=true
OLLAMA_COMPRESSION_RATIO=3

# ===========================================
# OLLAMA CONFIGURATION (RTX 4050 - 6GB VRAM)
# ===========================================
OLLAMA_BASE_URL=http://my-ollama-ip-server:11434
OLLAMA_TIMEOUT=180000
OLLAMA_MAX_RETRIES=2

# Contexto padrão para todos os modelos (8k tokens)
OLLAMA_DEFAULT_CONTEXT_SIZE=8192

# Configurações específicas por modelo (baseado nos seus modelos disponíveis)
# Modelos leves - contexto maior
OLLAMA_CONTEXT_MISTRAL_LATEST=4096
OLLAMA_CONTEXT_LLAMA3_1_LATEST=8192
OLLAMA_CONTEXT_PHI4_MINI_LATEST=4096
OLLAMA_CONTEXT_GRANITE3_3_8B=8192

# Modelos médios - contexto moderado
OLLAMA_CONTEXT_QWEN2_5_CODER_7B=4096
OLLAMA_CONTEXT_QWEN3_8B=4096
OLLAMA_CONTEXT_DEEPSEEK_R1_LATEST=6144
OLLAMA_CONTEXT_WHITERABBITNEO_2_5_QWEN_2_5_CODER_7B_LATEST=4096

# Compressão automática
OLLAMA_AUTO_COMPRESS=true
OLLAMA_COMPRESSION_RATIO=3

# Configurações de contexto RAG (sem hardcoding)
OLLAMA_DEFAULT_CONTEXT_LIMIT=1000
OLLAMA_LOCAL_CONTEXT_LIMIT=300
OLLAMA_AI_SYSTEM_CONTEXT_LIMIT=600
OLLAMA_LIMITED_CONTEXT_LIMIT=150

# Modelos com contexto limitado (configurável)
OLLAMA_LIMITED_CONTEXT_PHI4_MINI_LATEST=true
OLLAMA_LIMITED_CONTEXT_MISTRAL_LATEST=true
OLLAMA_LIMITED_CONTEXT_QWEN2_5_CODER_7B=true
OLLAMA_LIMITED_CONTEXT_QWEN3_8B=true

# Compressão agressiva por modelo (configurável)
OLLAMA_AGGRESSIVE_COMPRESS_PHI4_MINI_LATEST=true
OLLAMA_AGGRESSIVE_COMPRESS_MISTRAL_LATEST=true
OLLAMA_AGGRESSIVE_COMPRESS_QWEN2_5_CODER_7B=true
OLLAMA_AGGRESSIVE_COMPRESS_QWEN3_8B=true
