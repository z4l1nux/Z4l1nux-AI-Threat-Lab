import { OllamaEmbeddings } from "@langchain/community/embeddings/ollama";
import { OpenAIEmbeddings } from "@langchain/openai";
import { LanceDBSemanticSearch } from "./LanceDBSemanticSearch";
import { HybridSemanticSearch } from "./HybridSemanticSearch";
import { Neo4jSemanticSearch } from "./Neo4jSemanticSearch";

/**
 * Factory para criar inst칙ncias de busca sem칙ntica
 * Usa LanceDB como backend padr칚o
 */
export class SearchFactory {
  /**
   * Cria uma inst칙ncia de busca sem칙ntica (LanceDB por padr칚o)
   */
  static criarBusca(
    embeddings: any,
    arquivoCache: string = "vectorstore.json",
    pastaBase: string = "base",
    tipo: "lancedb" | "hibrida" | "neo4j" = "lancedb"
  ): LanceDBSemanticSearch | HybridSemanticSearch | Neo4jSemanticSearch {
    if (tipo === "hibrida") {
      console.log("游 Usando busca sem칙ntica H칈BRIDA (LanceDB + Neo4j)");
      return new HybridSemanticSearch(embeddings, "lancedb_cache", pastaBase);
    }
    if (tipo === "neo4j") {
      console.log("游 Usando busca sem칙ntica apenas NEO4J (칤ndice vetorial)");
      return new Neo4jSemanticSearch(embeddings);
    }
    console.log("游 Usando busca sem칙ntica com LanceDB");
    return new LanceDBSemanticSearch(embeddings, "lancedb_cache", pastaBase);
  }

  /**
   * Cria busca com LanceDB (padr칚o)
   */
  static criarBuscaLanceDB(
    embeddings: any,
    dbPath: string = "lancedb_cache",
    pastaBase: string = "base"
  ): LanceDBSemanticSearch {
    return new LanceDBSemanticSearch(embeddings, dbPath, pastaBase);
  }
}

