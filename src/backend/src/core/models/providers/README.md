# ğŸ”Œ Guia de Providers de IA

Este diretÃ³rio contÃ©m os **providers de modelos de IA** suportados pelo sistema de Threat Modeling.

## ğŸ“‹ **Ãndice**

1. [Providers DisponÃ­veis](#providers-disponÃ­veis)
2. [Arquitetura do Sistema](#arquitetura-do-sistema)
3. [Como Adicionar um Novo Provider](#como-adicionar-um-novo-provider)
4. [Exemplos PrÃ¡ticos](#exemplos-prÃ¡ticos)
5. [ReferÃªncia da Interface](#referÃªncia-da-interface)

---

## ğŸ¯ **Providers DisponÃ­veis**

| Provider | Arquivo | Suporta GeraÃ§Ã£o | Suporta Embeddings | Status |
|----------|---------|----------------|-------------------|--------|
| **Ollama** | `OllamaProvider.ts` | âœ… Sim | âœ… Sim | âœ… Ativo |
| **OpenRouter** | `OpenRouterProvider.ts` | âœ… Sim | âŒ NÃ£o | âœ… Ativo |
| **Gemini** | `GeminiProvider.ts` | âœ… Sim | âŒ NÃ£o | âœ… Ativo |
| **Template** | `TemplateProvider.ts` | ğŸ“– Exemplo | ğŸ“– Exemplo | ğŸ“– Template |

---

## ğŸ—ï¸ **Arquitetura do Sistema**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ModelFactory                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Auto-registro e gerenciamento de providers      â”‚  â”‚
â”‚  â”‚  - DetecÃ§Ã£o automÃ¡tica de disponibilidade        â”‚  â”‚
â”‚  â”‚  - Fallback entre providers                      â”‚  â”‚
â”‚  â”‚  - Sistema de prioridades                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                â”‚                â”‚
         â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ollama      â”‚  â”‚ OpenRouter   â”‚  â”‚ Gemini     â”‚
â”‚ Provider    â”‚  â”‚ Provider     â”‚  â”‚ Provider   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                 â”‚                 â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   ModelProvider          â”‚
           â”‚   (Interface)            â”‚
           â”‚   - generateContent()    â”‚
           â”‚   - generateEmbedding()  â”‚
           â”‚   - isAvailable()        â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ **Como Adicionar um Novo Provider**

### **Passo 1: Criar o Provider**

Copie o template e renomeie para seu provider:

```bash
cp TemplateProvider.ts AnthropicProvider.ts
```

### **Passo 2: Implementar a Interface**

Edite `AnthropicProvider.ts`:

```typescript
import { ModelProvider } from '../ModelProvider';

export class AnthropicProvider implements ModelProvider {
  name = 'anthropic'; // â† Nome Ãºnico do provider
  private apiKey: string;

  constructor() {
    // Carregar configuraÃ§Ãµes do .env
    this.apiKey = process.env.ANTHROPIC_API_KEY || '';
    console.log(`ğŸ”§ AnthropicProvider: API Key: ${this.apiKey ? 'Sim' : 'NÃ£o'}`);
  }

  async isAvailable(): Promise<boolean> {
    // Retorna true se o provider estÃ¡ configurado
    return !!this.apiKey;
  }

  async generateContent(prompt: string, model: string, format?: any): Promise<string> {
    // Implementar chamada Ã  API do Anthropic
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'x-api-key': this.apiKey,
        'anthropic-version': '2023-06-01',
        'content-type': 'application/json'
      },
      body: JSON.stringify({
        model,
        max_tokens: 4096,
        messages: [{ role: 'user', content: prompt }]
      })
    });

    const data = await response.json();
    return data.content[0].text;
  }

  async generateEmbedding(text: string, model: string): Promise<number[]> {
    // Se o provider nÃ£o suporta embeddings:
    throw new Error('AnthropicProvider nÃ£o suporta geraÃ§Ã£o de embeddings');
    
    // Ou implemente se suportar:
    // const response = await fetch(...);
    // return embedding;
  }
}
```

### **Passo 3: Registrar no ModelFactory**

Edite `../ModelFactory.ts`:

```typescript
import { AnthropicProvider } from './providers/AnthropicProvider';

// No mÃ©todo initialize(), adicione:
const anthropicProvider = new AnthropicProvider();
this.registerProvider(anthropicProvider);
```

### **Passo 4: Configurar VariÃ¡veis de Ambiente**

Adicione ao `backend/.env`:

```env
# Anthropic Configuration
ANTHROPIC_API_KEY=sk-ant-xxxxx
MODEL_ANTHROPIC=claude-3-5-sonnet-20241022
```

### **Passo 5: Atualizar Prioridades (Opcional)**

No `ModelFactory.ts`, ajuste as prioridades em `detectBestProvider()`:

```typescript
const priorities = ['ollama', 'anthropic', 'gemini', 'openrouter'];
```

### **Passo 6: Testar**

```bash
npm run build:backend
npm start
```

O provider serÃ¡ automaticamente detectado e registrado!

---

## ğŸ’¡ **Exemplos PrÃ¡ticos**

### **Exemplo 1: Provider Simples (Sem Embeddings)**

Provider para **Cohere** (apenas geraÃ§Ã£o de texto):

```typescript
import { ModelProvider } from '../ModelProvider';

export class CohereProvider implements ModelProvider {
  name = 'cohere';
  private apiKey: string;

  constructor() {
    this.apiKey = process.env.COHERE_API_KEY || '';
  }

  async isAvailable(): Promise<boolean> {
    return !!this.apiKey;
  }

  async generateContent(prompt: string, model: string): Promise<string> {
    const response = await fetch('https://api.cohere.ai/v1/generate', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model,
        prompt,
        max_tokens: 2000
      })
    });

    const data = await response.json();
    return data.generations[0].text;
  }

  async generateEmbedding(): Promise<number[]> {
    throw new Error('CohereProvider nÃ£o suporta embeddings (use outro provider)');
  }
}
```

### **Exemplo 2: Provider Completo (Com Embeddings)**

Provider para **OpenAI**:

```typescript
import { ModelProvider } from '../ModelProvider';

export class OpenAIProvider implements ModelProvider {
  name = 'openai';
  private apiKey: string;

  constructor() {
    this.apiKey = process.env.OPENAI_API_KEY || '';
  }

  async isAvailable(): Promise<boolean> {
    return !!this.apiKey;
  }

  async generateContent(prompt: string, model: string, format?: any): Promise<string> {
    const requestBody: any = {
      model,
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.7
    };

    // Suporte a structured output
    if (format) {
      requestBody.response_format = {
        type: "json_schema",
        json_schema: { name: "output", strict: true, schema: format }
      };
    }

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    });

    const data = await response.json();
    return data.choices[0].message.content;
  }

  async generateEmbedding(text: string, model: string): Promise<number[]> {
    const response = await fetch('https://api.openai.com/v1/embeddings', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({ model, input: text })
    });

    const data = await response.json();
    return data.data[0].embedding;
  }
}
```

### **Exemplo 3: Provider Local (Ollama-like)**

Provider para **LocalAI** (servidor local compatÃ­vel com OpenAI):

```typescript
import { ModelProvider } from '../ModelProvider';

export class LocalAIProvider implements ModelProvider {
  name = 'localai';
  private baseUrl: string;

  constructor() {
    this.baseUrl = process.env.LOCALAI_BASE_URL || 'http://localhost:8080';
  }

  async isAvailable(): Promise<boolean> {
    try {
      const response = await fetch(`${this.baseUrl}/v1/models`);
      return response.ok;
    } catch {
      return false;
    }
  }

  async generateContent(prompt: string, model: string): Promise<string> {
    const response = await fetch(`${this.baseUrl}/v1/chat/completions`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model,
        messages: [{ role: 'user', content: prompt }]
      })
    });

    const data = await response.json();
    return data.choices[0].message.content;
  }

  async generateEmbedding(text: string, model: string): Promise<number[]> {
    const response = await fetch(`${this.baseUrl}/v1/embeddings`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ model, input: text })
    });

    const data = await response.json();
    return data.data[0].embedding;
  }
}
```

---

## ğŸ“š **ReferÃªncia da Interface**

### **ModelProvider**

Interface que todos os providers devem implementar:

```typescript
export interface ModelProvider {
  // Nome Ãºnico do provider (ex: 'ollama', 'openrouter', 'anthropic')
  name: string;

  /**
   * Gera conteÃºdo de texto usando o modelo especificado
   * 
   * @param prompt - Prompt de entrada para o modelo
   * @param model - Nome/ID do modelo (ex: 'gpt-4', 'llama3.1:latest')
   * @param format - (Opcional) JSON Schema para structured output
   * @returns Promise<string> - Texto gerado ou JSON como string
   */
  generateContent(prompt: string, model: string, format?: any): Promise<string>;

  /**
   * Gera embeddings (vetores) para um texto
   * 
   * @param text - Texto para gerar embedding
   * @param model - Nome/ID do modelo de embedding
   * @returns Promise<number[]> - Vetor de embeddings
   * @throws Error se o provider nÃ£o suporta embeddings
   */
  generateEmbedding(text: string, model: string): Promise<number[]>;

  /**
   * Verifica se o provider estÃ¡ disponÃ­vel para uso
   * 
   * @returns Promise<boolean> - true se configurado e acessÃ­vel
   */
  isAvailable(): Promise<boolean>;
}
```

### **ModelConfig**

ConfiguraÃ§Ã£o de modelos passada ao Factory:

```typescript
export interface ModelConfig {
  model: string;              // Modelo principal (ex: 'llama3.1:latest')
  provider: string;           // Provider principal (ex: 'ollama')
  embedding: string;          // Modelo de embedding (ex: 'nomic-embed-text')
  embeddingProvider: string;  // Provider de embedding (ex: 'ollama')
}
```

---

## ğŸ” **Detalhes TÃ©cnicos**

### **Structured Output**

Para modelos que suportam structured output (JSON schema), o parÃ¢metro `format` deve seguir o padrÃ£o:

```typescript
const format = {
  type: 'object',
  properties: {
    threats: {
      type: 'array',
      items: {
        type: 'object',
        properties: {
          elementName: { type: 'string' },
          strideCategory: { type: 'string' },
          threatScenario: { type: 'string' }
        },
        required: ['elementName', 'strideCategory', 'threatScenario']
      }
    }
  },
  required: ['threats'],
  additionalProperties: false
};
```

### **Fallback AutomÃ¡tico**

O `ModelFactory` implementa fallback automÃ¡tico:

1. Tenta usar o provider especificado
2. Se falhar, detecta o melhor provider disponÃ­vel
3. Tenta novamente com o fallback

Prioridade padrÃ£o: `Ollama > Gemini > OpenRouter`

### **Timeout e Retry**

Cada provider deve implementar seu prÃ³prio mecanismo de timeout e retry. Exemplo:

```typescript
const controller = new AbortController();
const timeoutId = setTimeout(() => controller.abort(), 60000);

const response = await fetch(url, {
  signal: controller.signal
});

clearTimeout(timeoutId);
```

---

## ğŸ“ **Checklist para Novo Provider**

- [ ] Criar arquivo `YourProvider.ts` em `providers/`
- [ ] Implementar interface `ModelProvider`
- [ ] Definir propriedade `name` Ãºnica
- [ ] Implementar `isAvailable()`
- [ ] Implementar `generateContent()`
- [ ] Implementar `generateEmbedding()` (ou lanÃ§ar erro)
- [ ] Adicionar logs informativos (`console.log`)
- [ ] Registrar no `ModelFactory.ts`
- [ ] Adicionar variÃ¡veis de ambiente ao `.env.example`
- [ ] Testar em ambiente local
- [ ] Documentar no README.md (este arquivo)

---

## ğŸ¯ **PrÃ³ximos Passos**

Providers sugeridos para implementaÃ§Ã£o futura:

1. **AnthropicProvider** - Claude 3.5 Sonnet (excelente qualidade)
2. **OpenAIProvider** - GPT-4o, GPT-4 Turbo (referÃªncia de mercado)
3. **CohereProvider** - Command R+ (bom para RAG)
4. **MistralProvider** - Mixtral, Mistral Large (Europa, GDPR-friendly)
5. **LocalAIProvider** - Self-hosted alternativo ao Ollama
6. **AWSBedrockProvider** - Acesso a mÃºltiplos modelos via AWS
7. **AzureOpenAIProvider** - OpenAI via Azure (empresas)

---

## ğŸ“ **Suporte**

Para dÃºvidas ou problemas:

1. Consulte o `TemplateProvider.ts` como referÃªncia
2. Veja os providers existentes (`OllamaProvider.ts`, `OpenRouterProvider.ts`)
3. Leia a documentaÃ§Ã£o da API do provider que vocÃª estÃ¡ integrando
4. Teste com `npm run build:backend && npm start`

---

**Ãšltima atualizaÃ§Ã£o**: 2025-10-16
**VersÃ£o**: 1.0.0

