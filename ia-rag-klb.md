# ü§ñ Guia de Implementa√ß√£o: IA, RAG e Knowledge Base para Threat Modeling

> **Objetivo**: Este documento descreve as implementa√ß√µes avan√ßadas de detec√ß√£o autom√°tica de IA, sistema RAG inteligente e knowledge base especializada para threat modeling de sistemas com componentes de Machine Learning e Intelig√™ncia Artificial.

---

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Detec√ß√£o Autom√°tica de Componentes de IA](#detec√ß√£o-autom√°tica-de-componentes-de-ia)
3. [Sistema RAG Inteligente](#sistema-rag-inteligente)
4. [Knowledge Base Especializada](#knowledge-base-especializada)
5. [Integra√ß√£o DFD ‚Üí An√°lise Completa](#integra√ß√£o-dfd--an√°lise-completa)
6. [Deduplica√ß√£o e Prioriza√ß√£o](#deduplica√ß√£o-e-prioriza√ß√£o)
7. [C√≥digo Completo](#c√≥digo-completo)
8. [Estrutura de Arquivos](#estrutura-de-arquivos)
9. [Exemplos Pr√°ticos](#exemplos-pr√°ticos)

---

## üéØ Vis√£o Geral

### O Que Foi Implementado

Um **sistema inteligente** que:

‚úÖ **Detecta automaticamente** componentes de IA (LLM, ML, NLP, etc.)  
‚úÖ **Busca conhecimento espec√≠fico** no RAG quando IA √© detectada  
‚úÖ **Prioriza documentos-chave** (Kickoff, Arquitetura, Diagramas)  
‚úÖ **Deduplica por chunk espec√≠fico** (permite m√∫ltiplos chunks do mesmo doc)  
‚úÖ **Deduplica por vers√£o** (mant√©m apenas a vers√£o mais recente: `Sistema_X_2025-10-14`)  
‚úÖ **Analisa todos os fluxos do DFD** (tipo, criptografia, cross-boundary)  
‚úÖ **Integra knowledge base rica** (OWASP LLM, TRiSM, NIST RMF, Regula√ß√µes)

### Arquitetura do Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. SystemInfo + DFD Components                             ‚îÇ
‚îÇ     - Descri√ß√£o do sistema                                  ‚îÇ
‚îÇ     - Componentes, tecnologias, integra√ß√µes                 ‚îÇ
‚îÇ     - Fluxos de dados detalhados (do diagramConverter)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. detectAIComponents()                                    ‚îÇ
‚îÇ     - Analisa texto com 60+ palavras-chave                  ‚îÇ
‚îÇ     - Retorna: { hasAI, aiComponents[], confidence }        ‚îÇ
‚îÇ     - Confidence: HIGH, MEDIUM, LOW                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. searchRAGContext() - M√∫ltiplas Queries Paralelas        ‚îÇ
‚îÇ     Query 1: STRIDE geral                                   ‚îÇ
‚îÇ     Query 2: Componentes espec√≠ficos                        ‚îÇ
‚îÇ     Query 3: Tecnologias                                    ‚îÇ
‚îÇ     Query 4: Integra√ß√µes externas                           ‚îÇ
‚îÇ     Query 5: Perfis de usu√°rio                              ‚îÇ
‚îÇ     Query 6: OWASP LLM + TRiSM (se IA detectada) ‚≠ê         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. GeminiSearchFactory.buscarContextoRAG()                 ‚îÇ
‚îÇ     - Busca vetorial com Gemini embeddings                  ‚îÇ
‚îÇ     - Filtro por contexto de sistema                        ‚îÇ
‚îÇ     - Prioriza documentos-chave (Kickoff, Arquitetura)      ‚îÇ
‚îÇ     - Score threshold din√¢mico (0.55 key docs, 0.65 outros) ‚îÇ
‚îÇ     - Deduplica por chunk espec√≠fico                        ‚îÇ
‚îÇ     - Deduplica por vers√£o mais recente                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. Knowledge Base (Neo4j)                                  ‚îÇ
‚îÇ     üìö OWASP-LLM-Top-10.md                                  ‚îÇ
‚îÇ     üìö AI-TRiSM-Framework.md                                ‚îÇ
‚îÇ     üìö AI-Regulations-Compliance.md                         ‚îÇ
‚îÇ     üìö AI-Blind-Spots-Challenges.md                         ‚îÇ
‚îÇ     üìö NIST-AI-RMF.md (adicionar)                           ‚îÇ
‚îÇ     üìö CAPEC-STRIDE-mapping.csv                             ‚îÇ
‚îÇ     üìö Documentos de sistemas espec√≠ficos                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  6. Gemini API - An√°lise Completa                           ‚îÇ
‚îÇ     - Recebe SystemInfo completo                            ‚îÇ
‚îÇ     - Recebe an√°lise de fluxos do DFD                       ‚îÇ
‚îÇ     - Recebe contexto RAG (STRIDE + OWASP LLM)              ‚îÇ
‚îÇ     - Gera amea√ßas STRIDE + OWASP LLM + TRiSM               ‚îÇ
‚îÇ     - Retorna recomenda√ß√µes espec√≠ficas                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîç Detec√ß√£o Autom√°tica de Componentes de IA

### Arquivo: `src/services/aiThreatsKnowledgeBase.ts`

**Fun√ß√£o principal: `detectAIComponents()`**

```typescript
/**
 * Detec√ß√£o de Componentes de IA em Sistemas
 * 
 * Esta fun√ß√£o analisa o SystemInfo e identifica automaticamente
 * se o sistema cont√©m componentes de IA/ML.
 * 
 * Retorna: { hasAI: boolean, aiComponents: string[], confidence: 'HIGH' | 'MEDIUM' | 'LOW' }
 */

export function detectAIComponents(systemInfo: {
  generalDescription?: string;
  components?: string;
  technologies?: string;
  externalIntegrations?: string;
}): {
  hasAI: boolean;
  aiComponents: string[];
  confidence: 'HIGH' | 'MEDIUM' | 'LOW';
} {
  const textToAnalyze = [
    systemInfo.generalDescription || '',
    systemInfo.components || '',
    systemInfo.technologies || '',
    systemInfo.externalIntegrations || ''
  ].join(' ').toLowerCase();

  // ===== PALAVRAS-CHAVE DE IA (3 N√çVEIS DE CONFIAN√áA) =====
  
  const aiKeywords = {
    // Alta confian√ßa: Termos espec√≠ficos de IA/ML
    high: [
      'llm', 'large language model', 'gpt', 'gemini', 'claude', 'llama',
      'modelo de linguagem', 'machine learning', 'aprendizado de m√°quina',
      'deep learning', 'aprendizado profundo', 'rede neural', 'neural network',
      'intelig√™ncia artificial', 'artificial intelligence', 'ai', 'ia',
      'chatbot', 'assistente virtual', 'virtual assistant',
      'processamento de linguagem natural', 'nlp', 'natural language processing',
      'vis√£o computacional', 'computer vision', 'reconhecimento de imagem',
      'rag', 'retrieval augmented generation', 'embedding', 'vector database',
      'transformers', 'attention mechanism', 'bert', 'gpt-4', 'gpt-3'
    ],
    
    // M√©dia confian√ßa: Tecnologias/APIs relacionadas a IA
    medium: [
      'api openai', 'api anthropic', 'api google ai', 'hugging face',
      'tensorflow', 'pytorch', 'keras', 'scikit-learn', 'langchain',
      'modelo preditivo', 'predictive model', 'classifica√ß√£o', 'classification',
      'regress√£o', 'regression', 'clustering', 'agrupamento',
      'recomenda√ß√£o', 'recommendation', 'personaliza√ß√£o', 'personalization',
      'fine-tuning', 'prompt engineering', 'few-shot learning',
      'zero-shot', 'transfer learning', 'model training', 'inference'
    ],
    
    // Baixa confian√ßa: Termos gen√©ricos que podem indicar IA
    low: [
      'automa√ß√£o', 'automation', 'otimiza√ß√£o', 'optimization',
      'an√°lise de dados', 'data analysis', 'predi√ß√£o', 'prediction',
      'detec√ß√£o', 'detection', 'reconhecimento', 'recognition',
      'aprendizado', 'learning', 'treinamento', 'training'
    ]
  };

  let highConfidenceMatches: string[] = [];
  let mediumConfidenceMatches: string[] = [];
  let lowConfidenceMatches: string[] = [];

  // Detectar palavras-chave de alta confian√ßa
  aiKeywords.high.forEach(keyword => {
    if (textToAnalyze.includes(keyword)) {
      highConfidenceMatches.push(keyword);
    }
  });

  // Detectar palavras-chave de m√©dia confian√ßa
  aiKeywords.medium.forEach(keyword => {
    if (textToAnalyze.includes(keyword)) {
      mediumConfidenceMatches.push(keyword);
    }
  });

  // Detectar palavras-chave de baixa confian√ßa
  aiKeywords.low.forEach(keyword => {
    if (textToAnalyze.includes(keyword)) {
      lowConfidenceMatches.push(keyword);
    }
  });

  const allMatches = [...highConfidenceMatches, ...mediumConfidenceMatches, ...lowConfidenceMatches];
  const hasAI = allMatches.length > 0;

  // Determinar n√≠vel de confian√ßa
  let confidence: 'HIGH' | 'MEDIUM' | 'LOW';
  if (highConfidenceMatches.length > 0) {
    confidence = 'HIGH';
  } else if (mediumConfidenceMatches.length > 0) {
    confidence = 'MEDIUM';
  } else {
    confidence = 'LOW';
  }

  return {
    hasAI,
    aiComponents: allMatches,
    confidence: hasAI ? confidence : 'LOW'
  };
}
```

### Uso no Sistema

```typescript
// Em geminiService.ts (linha ~249)

// Detectar componentes de IA
const aiDetection = detectAIComponents(systemInfo);

if (aiDetection.hasAI) {
  console.log(`ü§ñ Sistema com IA detectado!`);
  console.log(`   Confian√ßa: ${aiDetection.confidence}`);
  console.log(`   Componentes identificados: ${aiDetection.aiComponents.slice(0, 5).join(', ')}`);
  
  // Adicionar query espec√≠fica para OWASP LLM + TRiSM
  searchQueries.push({
    query: 'OWASP LLM Top 10 prompt injection AI TRiSM intelig√™ncia artificial machine learning seguran√ßa IA threats vulnerabilities',
    aspect: 'Amea√ßas Espec√≠ficas de IA'
  });
}
```

---

## üîé Sistema RAG Inteligente

### M√∫ltiplas Queries Paralelas

O sistema realiza **6-9 queries RAG diferentes em paralelo** para capturar todos os aspectos do sistema:

```typescript
// Em geminiService.ts - Fun√ß√£o searchRAGContext()

const searchQueries: Array<{ query: string; aspect: string }> = [];

// 1. Query geral STRIDE
searchQueries.push({
  query: 'threat modeling STRIDE CAPEC security threats vulnerabilities',
  aspect: 'Modelagem de Amea√ßas STRIDE'
});

// 2. Query espec√≠fica de componentes
if (systemInfo.components) {
  searchQueries.push({
    query: `STRIDE threats for ${systemInfo.components}`,
    aspect: 'Amea√ßas dos Componentes'
  });
}

// 3. Query de tecnologias
if (systemInfo.technologies) {
  searchQueries.push({
    query: `security vulnerabilities ${systemInfo.technologies}`,
    aspect: 'Vulnerabilidades de Tecnologias'
  });
}

// 4. Query de integra√ß√µes externas
if (systemInfo.externalIntegrations && systemInfo.externalIntegrations !== 'Nenhuma identificada') {
  searchQueries.push({
    query: `third-party integration security risks ${systemInfo.externalIntegrations}`,
    aspect: 'Riscos de Integra√ß√µes Externas'
  });
}

// 5. Query de perfis de usu√°rio
if (systemInfo.userProfiles && systemInfo.userProfiles !== 'N√£o especificado') {
  searchQueries.push({
    query: `user authentication authorization STRIDE ${systemInfo.userProfiles}`,
    aspect: 'Seguran√ßa de Usu√°rios'
  });
}

// 6. Query de IA (SE DETECTADO) ‚≠ê‚≠ê‚≠ê
const aiDetection = detectAIComponents(systemInfo);
if (aiDetection.hasAI) {
  console.log(`ü§ñ Sistema com IA detectado (confian√ßa: ${aiDetection.confidence})`);
  searchQueries.push({
    query: 'OWASP LLM Top 10 prompt injection AI TRiSM intelig√™ncia artificial machine learning seguran√ßa IA threats vulnerabilities',
    aspect: 'Amea√ßas Espec√≠ficas de IA'
  });
}

// Executar todas as queries em paralelo
const searchPromises = searchQueries.map(async ({ query, aspect }) => {
  const response = await fetch(`${BACKEND_URL}/api/search/context`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ 
      query, 
      limit: 6,
      systemContext: systemInfo.systemName
    })
  });
  
  const context = await response.json();
  return { aspect, context };
});

const results = await Promise.all(searchPromises);
```

### Filtro por Contexto de Sistema

```typescript
// Em GeminiSearchFactory.ts - buscarContextoRAG()

if (systemContext && systemContext.trim().length > 0) {
  const systemNameLower = systemContext.toLowerCase().trim();
  
  // Extrair palavras-chave do sistema (ex: "Nomad Global Support System" -> ["nomad", "support", "system"])
  const systemKeywords = systemNameLower
    .split(/[\s\-_]+/)
    .filter(word => word.length > 3 && !['the', 'and', 'for', 'with'].includes(word));
  
  // Filtrar resultados relevantes
  const filteredResults = results.filter(result => {
    const docName = (result.documento.metadata.documentName || '').toLowerCase();
    const content = result.documento.pageContent.toLowerCase();
    
    // 1. SEMPRE manter documentos de framework (CAPEC-STRIDE, OWASP LLM, TRiSM)
    const isFrameworkDoc = docName.includes('stride') || docName.includes('capec') || 
        docName.includes('owasp') || docName.includes('trism') ||
        docName.includes('compliance') || docName.includes('ai-for');
    
    if (isFrameworkDoc) {
      return true; // Sempre incluir
    }
    
    // 2. PRIORIZAR documentos-chave (Kickoff, Arquitetura, Diagramas)
    const isKeyDocument = docName.includes('kickoff') || 
        docName.includes('arquitetura') || docName.includes('architecture') || 
        docName.includes('diagram') || docName.includes('mermaid');
    
    // 3. Verificar se menciona o sistema
    const mentionsSystem = systemKeywords.some(kw => 
      docName.includes(kw) || content.includes(kw)
    );
    
    return isKeyDocument || mentionsSystem;
  });
  
  console.log(`üîç Filtro de sistema "${systemContext}": ${results.length} ‚Üí ${filteredResults.length} documentos relevantes`);
  results = filteredResults;
}
```

---

## üìö Knowledge Base Especializada

### Estrutura de Documentos

```
knowledge-base/
‚îú‚îÄ‚îÄ OWASP-LLM-Top-10.md                 # 10 amea√ßas espec√≠ficas de LLM
‚îú‚îÄ‚îÄ AI-TRiSM-Framework.md               # Framework Gartner (4 pilares)
‚îú‚îÄ‚îÄ AI-Regulations-Compliance.md        # EU AI Act, GDPR, LGPD
‚îú‚îÄ‚îÄ AI-Blind-Spots-Challenges.md        # Desafios emergentes
‚îú‚îÄ‚îÄ NIST-AI-RMF.md                      # ‚≠ê NOVO - Adicionar
‚îú‚îÄ‚îÄ CAPEC-STRIDE-mapping.csv            # Mapeamento CAPEC ‚Üí STRIDE
‚îî‚îÄ‚îÄ sistemas/
    ‚îú‚îÄ‚îÄ Sistema_X_2025-10-14.md         # Vers√£o mais recente
    ‚îú‚îÄ‚îÄ Sistema_X_2025-10-13.md         # Vers√£o antiga (ignorada)
    ‚îî‚îÄ‚îÄ Sistema_Y_Kickoff.md            # Documento-chave
```

### 1. OWASP LLM Top 10 (Existente)

**Arquivo**: `knowledge-base/OWASP-LLM-Top-10.md`

**Conte√∫do**: 10 amea√ßas espec√≠ficas para sistemas com LLM:

- **LLM01** - Prompt Injection (CRITICAL)
- **LLM02** - Insecure Output Handling (HIGH)
- **LLM03** - Training Data Poisoning (CRITICAL)
- **LLM04** - Model Denial of Service (MEDIUM)
- **LLM05** - Supply Chain Vulnerabilities (HIGH)
- **LLM06** - Sensitive Information Disclosure (CRITICAL)
- **LLM07** - Insecure Plugin Design (HIGH)
- **LLM08** - Excessive Agency (MEDIUM)
- **LLM09** - Overreliance (MEDIUM)
- **LLM10** - Model Theft (MEDIUM)

Cada amea√ßa cont√©m:
- Descri√ß√£o detalhada
- Exemplos de ataque
- Mitiga√ß√µes espec√≠ficas
- CAPECs relacionados
- N√≠vel de impacto

### 2. AI TRiSM Framework (Existente)

**Arquivo**: `knowledge-base/AI-TRiSM-Framework.md`

**Conte√∫do**: Framework Gartner com 4 pilares:

1. **Explicabilidade e Monitoramento**
   - Transpar√™ncia em decis√µes
   - Detec√ß√£o de vieses
   - XAI (Explainable AI)
   - Ferramentas: SHAP, LIME, Model Cards

2. **ModelOps**
   - Ciclo de vida de modelos
   - CI/CD para ML
   - Versionamento e governan√ßa
   - Ferramentas: MLflow, Kubeflow

3. **Privacidade de IA**
   - Prote√ß√£o de dados de treinamento
   - Differential Privacy
   - Federated Learning
   - T√©cnicas: DP-SGD, PATE, Homomorphic Encryption

4. **Seguran√ßa de Aplica√ß√µes de IA**
   - Adversarial attacks
   - Model hardening
   - Input validation
   - T√©cnicas: Adversarial Training, Defensive Distillation

### 3. Regula√ß√µes e Compliance (Existente)

**Arquivo**: `knowledge-base/AI-Regulations-Compliance.md`

**Conte√∫do**:

- **EU AI Act** (2024)
  - Classifica√ß√£o de riscos
  - Requisitos para high-risk systems
  - Proibi√ß√µes

- **GDPR** (Aplicado a IA)
  - Direito √† explica√ß√£o
  - Automated decision-making
  - Data minimization

- **LGPD** (Brasil)
  - Tratamento de dados sens√≠veis
  - Automated decisions

- **ISO/IEC 42001** (AI Management System)

### 4. Desafios e Blind Spots (Existente)

**Arquivo**: `knowledge-base/AI-Blind-Spots-Challenges.md`

**Conte√∫do**:

- Alucina√ß√µes (Hallucinations)
- Envenenamento de dados (Data Poisoning)
- Ataques adversariais (Adversarial Attacks)
- Model inversion
- Membership inference
- Backdoor attacks
- Prompt leaking

### 5. NIST AI RMF (‚≠ê NOVO - Adicionar)

**Arquivo**: `knowledge-base/NIST-AI-RMF.md`

**Criar este arquivo com o seguinte conte√∫do:**

```markdown
# NIST AI Risk Management Framework (AI RMF)

## Vers√£o 1.0 - Janeiro 2023

**Fonte**: NIST Special Publication 800-248 (Draft)

---

## Vis√£o Geral

O NIST AI Risk Management Framework (AI RMF) fornece uma abordagem estruturada para gerenciar riscos de sistemas de IA ao longo de todo o ciclo de vida.

---

## As 4 Fun√ß√µes do AI RMF

### 1. GOVERN (Governar)

**Objetivo**: Estabelecer pol√≠ticas, procedimentos e cultura organizacional para gerenciar riscos de IA.

**Categorias**:
- **GOVERN 1.1**: Pol√≠ticas e responsabilidades claramente definidas
- **GOVERN 1.2**: Estruturas legais e regulat√≥rias compreendidas
- **GOVERN 1.3**: Processos de gest√£o de riscos estabelecidos
- **GOVERN 1.4**: Cultura organizacional que valoriza trustworthy AI
- **GOVERN 1.5**: Diversidade e inclus√£o na equipe de IA
- **GOVERN 1.6**: Estrutura de governan√ßa com accountability

**Controles Recomendados**:
- Criar AI Governance Board
- Definir AI Ethics Policy
- Implementar AI Impact Assessments
- Estabelecer mecanismos de accountability
- Documentar responsible AI principles

**Riscos Mitigados**:
- Uso n√£o √©tico de IA
- Falta de accountability
- N√£o conformidade regulat√≥ria
- Vieses sistem√°ticos n√£o endere√ßados

---

### 2. MAP (Mapear)

**Objetivo**: Estabelecer contexto para entender riscos relacionados ao sistema de IA.

**Categorias**:
- **MAP 1.1**: Contexto de neg√≥cio e caso de uso documentados
- **MAP 1.2**: Impactos sociot√©cnicos identificados
- **MAP 1.3**: Capacidades e limita√ß√µes do sistema AI compreendidas
- **MAP 1.4**: Riscos conhecidos documentados
- **MAP 1.5**: Stakeholders e suas preocupa√ß√µes identificados

**Atividades**:
- Documentar use case e objetivos do sistema
- Identificar stakeholders afetados
- Mapear dados de entrada/sa√≠da
- Avaliar impacto em grupos vulner√°veis
- Documentar suposi√ß√µes e limita√ß√µes do modelo
- Criar Model Card ou System Card

**Riscos Mitigados**:
- Uso inadequado do sistema
- Impactos n√£o intencionais
- Expectativas n√£o realistas
- Blind spots no design

---

### 3. MEASURE (Medir)

**Objetivo**: Usar m√©tricas para avaliar riscos de IA de forma quantitativa.

**Categorias**:
- **MEASURE 1.1**: M√©tricas apropriadas identificadas e implementadas
- **MEASURE 1.2**: Datasets de avalia√ß√£o representativos
- **MEASURE 2.1**: Vieses avaliados e documentados
- **MEASURE 2.2**: Robustez e reliability medidos
- **MEASURE 2.3**: Transparency e interpretability avaliados
- **MEASURE 2.4**: Privacy preservada e medida
- **MEASURE 2.5**: Safety risks quantificados
- **MEASURE 2.6**: Security vulnerabilities identificadas

**M√©tricas Recomendadas**:

**Fairness/Bias**:
- Disparate impact ratio
- Equal opportunity difference
- Demographic parity
- Individual fairness metrics

**Robustness**:
- Adversarial accuracy
- Out-of-distribution performance
- Input perturbation resilience

**Privacy**:
- Membership inference attack success rate
- Differential privacy epsilon
- Data leakage metrics

**Transparency**:
- Model complexity (# parameters)
- Explainability scores (LIME, SHAP)
- Decision boundary visualization

**Safety**:
- Error rate em cen√°rios cr√≠ticos
- Failure mode frequency
- Near-miss incidents

**Riscos Mitigados**:
- Vieses discriminat√≥rios
- Performance degradation
- Privacy breaches
- Safety incidents
- Security vulnerabilities

---

### 4. MANAGE (Gerenciar)

**Objetivo**: Priorizar e responder a riscos de IA de forma regular e cont√≠nua.

**Categorias**:
- **MANAGE 1.1**: Riscos de IA priorizados e resposta planejada
- **MANAGE 1.2**: Riscos de IA gerenciados continuamente
- **MANAGE 1.3**: Riscos comunicados aos stakeholders
- **MANAGE 1.4**: Incidentes documentados e aprendizados aplicados
- **MANAGE 2.1**: Monitoramento cont√≠nuo de riscos em produ√ß√£o
- **MANAGE 2.2**: Feedback loops estabelecidos
- **MANAGE 2.3**: Decommissioning respons√°vel quando apropriado
- **MANAGE 2.4**: Change management robusto

**Atividades de Gest√£o**:

**Pr√©-Deployment**:
- Red team testing
- Adversarial testing
- Bias auditing
- Safety testing
- Security assessments
- Penetration testing

**Produ√ß√£o**:
- Real-time monitoring dashboards
- Data drift detection
- Model drift detection
- Anomaly detection
- Performance degradation alerts
- Bias monitoring cont√≠nuo
- User feedback collection

**P√≥s-Incidente**:
- Incident response plan
- Root cause analysis
- Lessons learned documentation
- Model retraining se necess√°rio
- Communication plan

**Riscos Mitigados**:
- Incidentes n√£o detectados
- Degrada√ß√£o silenciosa de performance
- Falta de prepara√ß√£o para incidentes
- Aus√™ncia de accountability p√≥s-falha

---

## Caracter√≠sticas de Trustworthy AI (7 Pilares)

O NIST identifica 7 caracter√≠sticas que um sistema de IA confi√°vel deve ter:

### 1. Valid and Reliable
- Modelo performa conforme esperado
- Resultados consistentes e reprodut√≠veis
- Valida√ß√£o em datasets representativos

### 2. Safe
- N√£o causa harm f√≠sico ou psicol√≥gico
- Fail-safe mechanisms
- Emergency stop capabilities
- Testes de seguran√ßa rigorosos

### 3. Secure and Resilient
- Protegido contra ataques adversariais
- Resistente a data poisoning
- Input validation robusta
- Seguran√ßa de supply chain

### 4. Accountable and Transparent
- Decis√µes audit√°veis e rastre√°veis
- Documenta√ß√£o completa (Model Cards)
- Explicabilidade das decis√µes
- Clear ownership e responsibility

### 5. Explainable and Interpretable
- T√©cnicas XAI aplicadas (SHAP, LIME)
- Usu√°rios entendem como decis√µes s√£o tomadas
- Debugging facilitado
- Trust atrav√©s de transpar√™ncia

### 6. Privacy-Enhanced
- Minimiza√ß√£o de coleta de dados
- T√©cnicas de privacy preservation (Differential Privacy)
- Prote√ß√£o contra re-identification
- Conformidade com GDPR/LGPD

### 7. Fair - with Harmful Bias Managed
- Vieses identificados e mitigados
- Fairness metrics monitoradas
- Equitable outcomes para todos os grupos
- Auditorias regulares de fairness

---

## Mapping: NIST AI RMF ‚Üî STRIDE

| NIST AI RMF Category | STRIDE Threat | Descri√ß√£o |
|---------------------|---------------|-----------|
| MEASURE 2.6 (Security) | Tampering | Model tampering, data poisoning |
| MEASURE 2.4 (Privacy) | Information Disclosure | Data leakage, model inversion |
| MANAGE 2.1 (Monitoring) | Denial of Service | Model overload, resource exhaustion |
| GOVERN 1.6 (Accountability) | Repudiation | Lack of audit trails, n√£o-rastreabilidade |
| MEASURE 2.1 (Bias) | Elevation of Privilege | Unfair advantages para certos grupos |
| MEASURE 2.6 (Security) | Spoofing | Adversarial examples, input manipulation |

---

## Mapping: NIST AI RMF ‚Üî OWASP LLM Top 10

| NIST AI RMF Category | OWASP LLM Threat | Mitiga√ß√£o |
|---------------------|------------------|-----------|
| MEASURE 2.6 | LLM01 (Prompt Injection) | Input validation, prompt firewalls |
| MEASURE 2.2 | LLM02 (Insecure Output) | Output encoding, sandboxing |
| GOVERN 1.3 | LLM03 (Training Data Poisoning) | Data provenance, validation |
| MANAGE 2.1 | LLM04 (Model DoS) | Rate limiting, resource monitoring |
| MEASURE 2.6 | LLM05 (Supply Chain) | Dependency scanning, SBOMs |
| MEASURE 2.4 | LLM06 (Info Disclosure) | Data minimization, sanitization |
| GOVERN 1.5 | LLM07 (Insecure Plugin) | Plugin security review, sandboxing |
| GOVERN 1.6 | LLM08 (Excessive Agency) | Least privilege, authorization |
| MAP 1.3 | LLM09 (Overreliance) | User education, limitations disclosure |
| MEASURE 2.6 | LLM10 (Model Theft) | Access controls, watermarking |

---

## Implementa√ß√£o Pr√°tica

### Fase 1: GOVERN
```
‚úì Criar AI Governance Committee
‚úì Definir AI Ethics Policy
‚úì Estabelecer Responsible AI Principles
‚úì Definir accountability structure
```

### Fase 2: MAP
```
‚úì Documentar use case e objetivos
‚úì Criar Model Card
‚úì Identificar stakeholders e impactos
‚úì Mapear dados de entrada/sa√≠da
‚úì Documentar limita√ß√µes e suposi√ß√µes
```

### Fase 3: MEASURE
```
‚úì Implementar m√©tricas de fairness
‚úì Testar robustness (adversarial examples)
‚úì Avaliar privacy (membership inference)
‚úì Medir transparency (SHAP values)
‚úì Quantificar safety risks
‚úì Identificar vulnerabilidades de seguran√ßa
```

### Fase 4: MANAGE
```
‚úì Red team testing pr√©-deployment
‚úì Implementar monitoring dashboards
‚úì Configurar alertas de drift
‚úì Estabelecer incident response plan
‚úì Criar feedback loops
‚úì Documentar todos os incidentes
```

---

## Ferramentas e Frameworks Compat√≠veis

### Governan√ßa
- **AI Governance Board Templates** (Google, Microsoft)
- **Model Cards** (Google)
- **System Cards** (OpenAI)
- **Datasheets for Datasets** (Microsoft)

### Measurement
- **Fairness**: Fairlearn, AI Fairness 360 (IBM), Aequitas
- **Privacy**: Differential Privacy (TensorFlow, PyTorch), Opacus
- **Explainability**: SHAP, LIME, InterpretML, Captum
- **Robustness**: Adversarial Robustness Toolbox (ART), CleverHans
- **Monitoring**: Evidently AI, WhyLabs, Fiddler AI

### Management
- **MLOps**: MLflow, Kubeflow, Weights & Biases
- **Monitoring**: Prometheus, Grafana, Datadog
- **Incident Management**: PagerDuty, OpsGenie

---

## Compliance e Certifica√ß√£o

O NIST AI RMF alinha com:

- ‚úÖ **EU AI Act** (High-Risk AI Systems Requirements)
- ‚úÖ **ISO/IEC 42001** (AI Management System)
- ‚úÖ **ISO/IEC 23894** (AI Risk Management)
- ‚úÖ **ISO/IEC 27001** (Information Security)
- ‚úÖ **GDPR** Article 22 (Automated Decision-Making)
- ‚úÖ **SOC 2** Type II (AI-specific controls)

---

## Refer√™ncias

- NIST AI Risk Management Framework (AI RMF 1.0): https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf
- NIST AI 100-2 series (Implementation Guidance)
- NIST Trustworthy and Responsible AI Resource Center

---

**√öltima Atualiza√ß√£o**: Outubro 2025
**Vers√£o**: 1.0 baseada em NIST AI RMF 1.0
```

---

## üîÑ Integra√ß√£o DFD ‚Üí An√°lise Completa

### Como os Componentes do DFD s√£o Inclu√≠dos

**1. Convers√£o do Diagrama** (`diagramConverter.ts`):

```typescript
export function convertDiagramToSystemInfo(
  nodes: Node[],
  edges: Edge[],
  systemName: string
): SystemInfo {
  // ... extra√ß√£o de componentes, dados, tech, etc ...
  
  // ===== AN√ÅLISE COMPLETA DOS FLUXOS =====
  
  const dataFlows = edges.map(e => {
    const source = nodes.find(n => n.id === e.source);
    const target = nodes.find(n => n.id === e.target);
    const dataType = e.data?.dataType || 'n√£o especificado';
    const encrypted = e.data?.encrypted ? 'üîí' : '‚ö†Ô∏è n√£o criptografado';
    
    return `  ‚Ä¢ ${source.data.label} ‚Üí ${target.data.label}
    - Tipo: ${dataType} (${encrypted})`;
  }).join('\n\n');
  
  // Detectar fluxos de risco
  const unencryptedFlows = edges.filter(e => !e.data?.encrypted);
  const sensitiveFlows = edges.filter(e => 
    e.data?.dataType?.includes('sens√≠veis') || 
    e.data?.dataType?.includes('credenciais')
  );
  const crossBoundaryFlows = detectCrossBoundary(nodes, edges);
  
  // Construir contexto rico
  let additionalContext = `
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìä AN√ÅLISE DETALHADA DO DIAGRAMA VISUAL
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üîç ESTAT√çSTICAS:
  ‚Ä¢ Componentes: ${nodes.length}
  ‚Ä¢ Fluxos: ${edges.length}
  ‚Ä¢ Trust boundaries: ${boundaries.length}

üö® RISCOS IDENTIFICADOS:
  ‚Ä¢ Fluxos n√£o criptografados: ${unencryptedFlows.length} ‚ö†Ô∏è
  ‚Ä¢ Dados sens√≠veis: ${sensitiveFlows.length} ‚ö†Ô∏è
  ‚Ä¢ Cross-boundary: ${crossBoundaryFlows.length} ‚ö†Ô∏è

üì¶ FLUXOS DETALHADOS:
${dataFlows}
`;

  if (unencryptedFlows.length > 0) {
    additionalContext += `\n‚ö†Ô∏è ALERTA: Fluxos sem criptografia detectados!
Recomenda√ß√£o: Implementar TLS/SSL`;
  }

  return {
    systemName,
    generalDescription,
    components,
    sensitiveData,
    technologies,
    authentication,
    userProfiles,
    externalIntegrations,
    additionalContext  // ‚≠ê Enviado para a IA
  };
}
```

**2. A IA recebe TODO o contexto**:

```typescript
// Em geminiService.ts

const prompt = `
Voc√™ √© um especialista em threat modeling...

===== INFORMA√á√ïES DO SISTEMA =====
Nome: ${systemInfo.systemName}
Descri√ß√£o: ${systemInfo.generalDescription}
Componentes: ${systemInfo.components}
...

${systemInfo.additionalContext}  // ‚≠ê Inclui an√°lise completa do DFD

===== CONTEXTO RAG (Knowledge Base) =====
${ragContext}

===== AN√ÅLISE DE IA =====
${aiDetection.hasAI ? 'Sistema com componentes de IA detectados' : ''}

Analise TODOS os componentes, fluxos e riscos identificados...
`;
```

---

## ‚öôÔ∏è Deduplica√ß√£o e Prioriza√ß√£o

### 1. Deduplica√ß√£o por Chunk Espec√≠fico

**Problema**: Mesmo chunk aparecia m√∫ltiplas vezes nos resultados.

**Solu√ß√£o**: Deduplica por `documentId::chunkIndex`, permitindo m√∫ltiplos chunks diferentes do mesmo documento.

```typescript
// Em GeminiSearchFactory.ts (linhas 161-186)

const seenChunks = new Set<string>();
const uniqueResults: typeof results = [];

for (const result of results) {
  const docId = result.documento.metadata.documentId || 'unknown';
  const docName = result.documento.metadata.documentName || 'unknown';
  const chunkIndex = result.documento.metadata.chunkIndex ?? 'unknown';
  
  // Chave √∫nica: documento + chunk
  const documentKey = docId !== 'unknown' ? docId : docName;
  const chunkKey = `${documentKey}::${chunkIndex}`;
  
  if (!seenChunks.has(chunkKey)) {
    seenChunks.add(chunkKey);
    uniqueResults.push(result);
  }
}

results = uniqueResults;
console.log(`‚úÇÔ∏è Deduplica√ß√£o por chunk: ${originalCount} ‚Üí ${results.length} chunks √∫nicos`);
```

### 2. Deduplica√ß√£o por Vers√£o Mais Recente

**Problema**: M√∫ltiplas vers√µes do mesmo documento no sistema (`Sistema_X_2025-10-09`, `Sistema_X_2025-10-14`).

**Solu√ß√£o**: Detecta padr√£o `_YYYY-MM-DD` e mant√©m apenas a vers√£o mais recente.

```typescript
// Em GeminiSearchFactory.ts (linhas 188-240)

const documentsByBaseName = new Map();

for (const result of results) {
  const docName = result.documento.metadata.documentName || 'unknown';
  
  // Regex para detectar timestamp no nome: Sistema_X_2025-10-14
  const baseNameMatch = docName.match(/^(.+?)_(\d{4}-\d{2}-\d{2})$/);
  
  if (baseNameMatch) {
    const baseName = baseNameMatch[1];  // "Sistema_X"
    const timestamp = baseNameMatch[2];  // "2025-10-14"
    
    if (!documentsByBaseName.has(baseName)) {
      documentsByBaseName.set(baseName, []);
    }
    documentsByBaseName.get(baseName).push({ result, baseName, timestamp });
  } else {
    // Documento sem timestamp, adicionar direto
    deduplicatedResults.push(result);
  }
}

// Para cada grupo, manter apenas a vers√£o mais recente
documentsByBaseName.forEach((docs, baseName) => {
  if (docs.length > 1) {
    // Ordenar por timestamp (mais recente primeiro)
    docs.sort((a, b) => b.timestamp.localeCompare(a.timestamp));
    
    const mostRecent = docs[0];
    deduplicatedResults.push(mostRecent.result);
    
    console.log(`üìÖ Vers√µes do documento "${baseName}": mantida ${mostRecent.timestamp}, removidas ${docs.length - 1} vers√µes antigas`);
  } else {
    deduplicatedResults.push(docs[0].result);
  }
});

results = deduplicatedResults;
```

### 3. Prioriza√ß√£o de Documentos-Chave

**Documentos-chave recebem tratamento especial**:

```typescript
// Em GeminiSearchFactory.ts (linhas 94-115)

// Priorizar documentos importantes
const isKeyDocument = docName.includes('kickoff') || 
    docName.includes('arquitetura') || docName.includes('architecture') || 
    docName.includes('diagram') || docName.includes('mermaid');

// Score threshold mais flex√≠vel para documentos-chave
let scoreThreshold = 0.65; // Padr√£o

if (isKeyDocument) {
  scoreThreshold = 0.55; // Mais flex√≠vel
  
  // Se tem palavras-chave do sistema, ainda mais flex√≠vel
  if (mentionsSystemKeywords) {
    scoreThreshold = 0.50;
  }
}

// Filtrar por score
if (result.score >= scoreThreshold) {
  // Incluir
}
```

### 4. Garantia de Documentos-Chave

**Garante que pelo menos 2 chunks de documentos-chave sejam inclu√≠dos**:

```typescript
// Em GeminiSearchFactory.ts (linhas 120-143)

// Contar quantos chunks de docs-chave temos
const keyDocumentChunks = results.filter(r => {
  const docName = r.documento.metadata.documentName || '';
  return docName.includes('kickoff') || docName.includes('arquitetura') || 
         docName.includes('diagram') || docName.includes('mermaid');
});

console.log(`üìå Chunks de documentos-chave: ${keyDocumentChunks.length}`);

// Se tiver menos de 2, buscar mais
if (keyDocumentChunks.length < 2) {
  const additionalKeyDocs = allResults
    .filter(r => {
      const docName = r.documento.metadata.documentName || '';
      return (docName.includes('kickoff') || docName.includes('arquitetura') || 
              docName.includes('diagram')) && 
             !results.some(existing => existing.documento.metadata.documentId === r.documento.metadata.documentId);
    })
    .slice(0, 2 - keyDocumentChunks.length);
  
  results.push(...additionalKeyDocs);
  console.log(`üìå Adicionados ${additionalKeyDocs.length} chunks de docs-chave para garantir cobertura`);
}
```

---

## üíª C√≥digo Completo

### Arquivo 1: `src/services/aiThreatsKnowledgeBase.ts`

```typescript
/**
 * Detec√ß√£o de Componentes de IA em Sistemas
 * 
 * NOTA: O conhecimento sobre amea√ßas de IA foi migrado para documentos RAG:
 * - OWASP-LLM-Top-10.md
 * - AI-TRiSM-Framework.md
 * - AI-Regulations-Compliance.md
 * - AI-Blind-Spots-Challenges.md
 * - NIST-AI-RMF.md
 */

export function detectAIComponents(systemInfo: {
  generalDescription?: string;
  components?: string;
  technologies?: string;
  externalIntegrations?: string;
}): {
  hasAI: boolean;
  aiComponents: string[];
  confidence: 'HIGH' | 'MEDIUM' | 'LOW';
} {
  const textToAnalyze = [
    systemInfo.generalDescription || '',
    systemInfo.components || '',
    systemInfo.technologies || '',
    systemInfo.externalIntegrations || ''
  ].join(' ').toLowerCase();

  const aiKeywords = {
    high: [
      'llm', 'large language model', 'gpt', 'gemini', 'claude', 'llama',
      'modelo de linguagem', 'machine learning', 'aprendizado de m√°quina',
      'deep learning', 'aprendizado profundo', 'rede neural', 'neural network',
      'intelig√™ncia artificial', 'artificial intelligence', 'ai', 'ia',
      'chatbot', 'assistente virtual', 'virtual assistant',
      'processamento de linguagem natural', 'nlp', 'natural language processing',
      'vis√£o computacional', 'computer vision', 'reconhecimento de imagem',
      'rag', 'retrieval augmented generation', 'embedding', 'vector database'
    ],
    medium: [
      'api openai', 'api anthropic', 'api google ai', 'hugging face',
      'tensorflow', 'pytorch', 'keras', 'scikit-learn', 'langchain',
      'modelo preditivo', 'predictive model', 'classifica√ß√£o', 'classification',
      'regress√£o', 'regression', 'clustering', 'agrupamento',
      'recomenda√ß√£o', 'recommendation', 'personaliza√ß√£o', 'personalization',
      'bert', 'transformer', 'attention mechanism', 'fine-tuning', 'prompt'
    ],
    low: [
      'automa√ß√£o', 'automation', 'otimiza√ß√£o', 'optimization',
      'an√°lise de dados', 'data analysis', 'predi√ß√£o', 'prediction',
      'detec√ß√£o', 'detection', 'reconhecimento', 'recognition',
      'aprendizado', 'learning', 'treinamento', 'training'
    ]
  };

  let highConfidenceMatches: string[] = [];
  let mediumConfidenceMatches: string[] = [];
  let lowConfidenceMatches: string[] = [];

  aiKeywords.high.forEach(keyword => {
    if (textToAnalyze.includes(keyword)) {
      highConfidenceMatches.push(keyword);
    }
  });

  aiKeywords.medium.forEach(keyword => {
    if (textToAnalyze.includes(keyword)) {
      mediumConfidenceMatches.push(keyword);
    }
  });

  aiKeywords.low.forEach(keyword => {
    if (textToAnalyze.includes(keyword)) {
      lowConfidenceMatches.push(keyword);
    }
  });

  const allMatches = [...highConfidenceMatches, ...mediumConfidenceMatches, ...lowConfidenceMatches];
  const hasAI = allMatches.length > 0;

  let confidence: 'HIGH' | 'MEDIUM' | 'LOW';
  if (highConfidenceMatches.length > 0) {
    confidence = 'HIGH';
  } else if (mediumConfidenceMatches.length > 0) {
    confidence = 'MEDIUM';
  } else {
    confidence = 'LOW';
  }

  return {
    hasAI,
    aiComponents: allMatches,
    confidence: hasAI ? confidence : 'LOW'
  };
}
```

### Arquivo 2: `src/services/geminiService.ts` (Trechos Relevantes)

```typescript
import { detectAIComponents } from './aiThreatsKnowledgeBase';

async function searchRAGContext(systemInfo: SystemInfo): Promise<string> {
  const searchQueries: Array<{ query: string; aspect: string }> = [];

  // 1. Query geral STRIDE
  searchQueries.push({
    query: 'threat modeling STRIDE CAPEC security threats vulnerabilities',
    aspect: 'Modelagem de Amea√ßas STRIDE'
  });

  // 2-5. Queries espec√≠ficas de componentes, tech, integra√ß√µes, usu√°rios
  // ... (c√≥digo j√° mostrado anteriormente)

  // 6. Query de IA SE DETECTADO ‚≠ê
  const aiDetection = detectAIComponents(systemInfo);
  if (aiDetection.hasAI) {
    console.log(`ü§ñ Sistema com IA detectado (confian√ßa: ${aiDetection.confidence})`);
    searchQueries.push({
      query: 'OWASP LLM Top 10 prompt injection AI TRiSM NIST AI RMF intelig√™ncia artificial machine learning seguran√ßa IA threats vulnerabilities',
      aspect: 'Amea√ßas Espec√≠ficas de IA'
    });
  }

  // Executar queries em paralelo
  const searchPromises = searchQueries.map(async ({ query, aspect }) => {
    const response = await fetch(`${BACKEND_URL}/api/search/context`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ 
        query, 
        limit: 6,
        systemContext: systemInfo.systemName
      })
    });
    
    const context = await response.json();
    return { aspect, context };
  });

  const results = await Promise.all(searchPromises);

  // Combinar resultados deduplicados
  const allSources: any[] = [];
  const seenChunkIds = new Set<string>();
  
  results.forEach(result => {
    result.context.sources.forEach((source: any) => {
      const chunkId = `${source.documento.metadata.documentId}-${source.documento.metadata.chunkIndex}`;
      if (!seenChunkIds.has(chunkId)) {
        seenChunkIds.add(chunkId);
        allSources.push({
          ...source,
          searchAspect: result.aspect
        });
      }
    });
  });

  // Construir contexto final
  let finalContext = '===== CONTEXTO RAG (Knowledge Base) =====\n\n';
  
  allSources.forEach((source, index) => {
    finalContext += `--- Fonte ${index + 1} (${source.searchAspect}) ---\n`;
    finalContext += `Documento: ${source.documento.metadata.documentName}\n`;
    finalContext += `Conte√∫do:\n${source.documento.pageContent}\n\n`;
  });

  return finalContext;
}

export async function generateThreatModel(systemInfo: SystemInfo): Promise<ThreatModelResponse> {
  // 1. Detectar IA
  const aiDetection = detectAIComponents(systemInfo);
  
  // 2. Buscar contexto RAG (inclui query de IA se detectado)
  const ragContext = await searchRAGContext(systemInfo);
  
  // 3. Construir prompt completo
  const prompt = `
Voc√™ √© um especialista em threat modeling e seguran√ßa cibern√©tica...

===== INFORMA√á√ïES DO SISTEMA =====
Nome: ${systemInfo.systemName}
Descri√ß√£o: ${systemInfo.generalDescription}
Componentes: ${systemInfo.components}
Dados Sens√≠veis: ${systemInfo.sensitiveData}
Tecnologias: ${systemInfo.technologies}
Autentica√ß√£o: ${systemInfo.authentication}
Perfis de Usu√°rio: ${systemInfo.userProfiles}
Integra√ß√µes Externas: ${systemInfo.externalIntegrations}

${systemInfo.additionalContext || ''}

===== AN√ÅLISE DE IA =====
${aiDetection.hasAI ? `
‚ö†Ô∏è SISTEMA COM COMPONENTES DE IA DETECTADOS
Confian√ßa: ${aiDetection.confidence}
Componentes: ${aiDetection.aiComponents.slice(0, 10).join(', ')}

IMPORTANTE: Considere amea√ßas espec√≠ficas de IA:
- OWASP LLM Top 10 (prompt injection, data poisoning, etc.)
- AI TRiSM (explicabilidade, ModelOps, privacidade, seguran√ßa)
- NIST AI RMF (GOVERN, MAP, MEASURE, MANAGE)
- Vieses, alucina√ß√µes, adversarial attacks
` : 'Sistema sem componentes de IA detectados.'}

${ragContext}

===== SUA TAREFA =====
Analise TODOS os componentes, fluxos de dados e integra√ß√µes.
Para sistemas com IA, considere OWASP LLM Top 10, AI TRiSM e NIST AI RMF.
Gere amea√ßas STRIDE com:
- Categoria STRIDE
- Descri√ß√£o detalhada
- Severidade (CRITICAL, HIGH, MEDIUM, LOW)
- CAPECs relacionados
- Mitiga√ß√µes espec√≠ficas

Retorne JSON conforme schema...
`;

  // 4. Chamar Gemini API
  const response = await callGeminiAPI(prompt);
  
  return response;
}
```

---

## üìÅ Estrutura de Arquivos Completa

```
projeto/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ core/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ search/
‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ GeminiSearchFactory.ts      # Busca RAG + deduplica√ß√£o
‚îÇ       ‚îî‚îÄ‚îÄ cache/
‚îÇ           ‚îî‚îÄ‚îÄ Neo4jCacheManager.ts            # Gest√£o Neo4j
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ geminiService.ts                    # Orquestra√ß√£o principal
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ aiThreatsKnowledgeBase.ts          # Detec√ß√£o de IA
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ diagramConverter.ts                 # DFD ‚Üí SystemInfo
‚îÇ
‚îú‚îÄ‚îÄ knowledge-base/
‚îÇ   ‚îú‚îÄ‚îÄ OWASP-LLM-Top-10.md                    # ‚úÖ Existente
‚îÇ   ‚îú‚îÄ‚îÄ AI-TRiSM-Framework.md                  # ‚úÖ Existente
‚îÇ   ‚îú‚îÄ‚îÄ AI-Regulations-Compliance.md           # ‚úÖ Existente
‚îÇ   ‚îú‚îÄ‚îÄ AI-Blind-Spots-Challenges.md           # ‚úÖ Existente
‚îÇ   ‚îú‚îÄ‚îÄ NIST-AI-RMF.md                         # ‚≠ê CRIAR
‚îÇ   ‚îú‚îÄ‚îÄ CAPEC-STRIDE-mapping.csv               # ‚úÖ Existente
‚îÇ   ‚îî‚îÄ‚îÄ sistemas/
‚îÇ       ‚îú‚îÄ‚îÄ Sistema_X_2025-10-14.md            # Vers√£o mais recente
‚îÇ       ‚îî‚îÄ‚îÄ Sistema_Y_Kickoff.md               # Documento-chave
‚îÇ
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ VISUAL-EDITOR-IMPLEMENTATION-GUIDE.md  # Guia do editor
    ‚îî‚îÄ‚îÄ AI-RAG-KNOWLEDGE-BASE-GUIDE.md        # Este documento
```

---

## üöÄ Exemplos Pr√°ticos

### Exemplo 1: Sistema com LLM Chatbot

**Input (DFD)**:
```json
{
  "systemName": "Customer Support Chatbot",
  "components": "Web App, LLM Model (GPT-4), Vector Database, Auth Service",
  "technologies": "OpenAI API, Pinecone, React, Node.js",
  "dataFlows": [
    { "from": "User", "to": "Web App", "type": "HTTPS", "encrypted": true },
    { "from": "Web App", "to": "LLM Model", "type": "API REST", "dataType": "prompts" },
    { "from": "LLM Model", "to": "OpenAI API", "type": "HTTPS", "encrypted": true }
  ]
}
```

**Processamento**:

1. **`detectAIComponents()`** detecta:
   ```json
   {
     "hasAI": true,
     "aiComponents": ["llm", "gpt-4", "chatbot", "api openai"],
     "confidence": "HIGH"
   }
   ```

2. **`searchRAGContext()`** executa 6 queries:
   - Query 1: STRIDE geral
   - Query 2: Componentes (Web App, LLM, Vector DB)
   - Query 3: Tecnologias (OpenAI, Pinecone, React)
   - Query 4: Auth Service
   - Query 5: Usu√°rios
   - **Query 6: OWASP LLM + TRiSM** ‚≠ê

3. **RAG retorna**:
   - CAPEC-STRIDE mappings
   - **OWASP-LLM-Top-10.md** (LLM01, LLM02, LLM06)
   - **AI-TRiSM-Framework.md** (4 pilares)
   - **NIST-AI-RMF.md** (GOVERN, MEASURE, MANAGE)
   - Documento do sistema (se existir)

4. **An√°lise da IA**:
   ```
   ===== AMEA√áAS IDENTIFICADAS =====
   
   **LLM01 - Prompt Injection** (CRITICAL)
   - Descri√ß√£o: Usu√°rio pode manipular prompts para extrair system instructions
   - Mitiga√ß√£o: Implementar prompt firewall, separar instru√ß√µes de entrada do usu√°rio
   - CAPEC: CAPEC-242 (Code Injection)
   
   **Information Disclosure** (STRIDE) (HIGH)
   - Descri√ß√£o: LLM pode vazar dados sens√≠veis no vector database
   - Mitiga√ß√£o: Sanitizar dados antes de armazenar, limitar acesso
   - CAPEC: CAPEC-116 (Data Leakage)
   
   **AI TRiSM - Falta de Explicabilidade** (MEDIUM)
   - Descri√ß√£o: Decis√µes do chatbot n√£o s√£o audit√°veis
   - Mitiga√ß√£o: Implementar logging de decis√µes, Model Cards
   
   **NIST AI RMF - MEASURE 2.1 (Bias)** (MEDIUM)
   - Descri√ß√£o: Modelo pode ter vieses n√£o detectados
   - Mitiga√ß√£o: Auditorias regulares de fairness, m√©tricas de vi√©s
   ```

---

### Exemplo 2: Sistema sem IA (Web App Tradicional)

**Input**:
```json
{
  "systemName": "E-commerce Platform",
  "components": "Web App, API Gateway, Database, Payment Service",
  "technologies": "React, Node.js, PostgreSQL, Stripe",
  "dataFlows": [
    { "from": "User", "to": "Web App", "type": "HTTPS" },
    { "from": "Web App", "to": "API Gateway", "type": "HTTPS" },
    { "from": "API Gateway", "to": "Database", "type": "SQL" }
  ]
}
```

**Processamento**:

1. **`detectAIComponents()`** retorna:
   ```json
   {
     "hasAI": false,
     "aiComponents": [],
     "confidence": "LOW"
   }
   ```

2. **`searchRAGContext()`** executa **5 queries** (sem query de IA):
   - Query 1: STRIDE geral
   - Query 2: Web App, API Gateway, Database
   - Query 3: React, Node.js, PostgreSQL
   - Query 4: Stripe (integra√ß√£o externa)
   - Query 5: Usu√°rios

3. **RAG retorna**:
   - CAPEC-STRIDE mappings
   - Documentos gerais de seguran√ßa web
   - Documento do sistema (se existir)

4. **An√°lise da IA**:
   ```
   ===== AMEA√áAS IDENTIFICADAS =====
   
   **SQL Injection** (STRIDE: Tampering) (CRITICAL)
   - Descri√ß√£o: API Gateway pode executar queries SQL maliciosos
   - Mitiga√ß√£o: Usar prepared statements, validar entradas
   - CAPEC: CAPEC-66
   
   **Information Disclosure** (HIGH)
   - Descri√ß√£o: Database pode vazar dados de cart√£o de cr√©dito
   - Mitiga√ß√£o: Criptografar dados em repouso, seguir PCI DSS
   - CAPEC: CAPEC-116
   
   **Denial of Service** (MEDIUM)
   - Descri√ß√£o: API Gateway pode ser sobrecarregada
   - Mitiga√ß√£o: Rate limiting, CDN, auto-scaling
   - CAPEC: CAPEC-469
   ```

---

### Exemplo 3: Fluxo N√£o Criptografado (Detectado Automaticamente)

**Input (DFD)**:
```json
{
  "dataFlows": [
    {
      "from": "Web App",
      "to": "Database",
      "label": "User credentials",
      "type": "HTTP",  // ‚ö†Ô∏è N√£o criptografado!
      "encrypted": false,
      "dataType": "credenciais"
    }
  ]
}
```

**`diagramConverter.ts` detecta**:
```typescript
const unencryptedFlows = edges.filter(e => !e.data?.encrypted);
// unencryptedFlows.length = 1

const additionalContext = `
‚ö†Ô∏è ALERTA DE SEGURAN√áA - Fluxos n√£o criptografados detectados:
  ‚Ä¢ Web App ‚Üí Database (HTTP) - credenciais

Recomenda√ß√£o: Implementar TLS/SSL para proteger dados em tr√¢nsito.

RISCO: CRITICAL
- Information Disclosure (STRIDE)
- Tampering (STRIDE)
- CAPECs: CAPEC-117 (Interception), CAPEC-94 (Man-in-the-Middle)
`;
```

**An√°lise da IA**:
```
===== AMEA√áAS CR√çTICAS =====

**Information Disclosure** (CRITICAL) ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
- Descri√ß√£o: Credenciais de usu√°rio trafegam sem criptografia (HTTP)
- Impacto: Atacante pode interceptar senhas em texto plano
- Probabilidade: ALTA (ferramentas como Wireshark facilmente capturam)
- Mitiga√ß√£o URGENTE:
  1. Configurar TLS 1.3 imediatamente
  2. Redirecionar todo tr√°fego HTTP para HTTPS (HTTP 301)
  3. Implementar HSTS (HTTP Strict Transport Security)
  4. Usar certificado v√°lido (Let's Encrypt gratuito)
- CAPEC: CAPEC-117 (Interception), CAPEC-94 (MITM)
- Compliance: Viola GDPR Art. 32, PCI DSS Req. 4.1, LGPD Art. 46
```

---

## ‚úÖ Checklist de Implementa√ß√£o

### Detec√ß√£o de IA
- [ ] `aiThreatsKnowledgeBase.ts` criado com `detectAIComponents()`
- [ ] 60+ palavras-chave de IA configuradas (high/medium/low)
- [ ] Retorno de `{ hasAI, aiComponents[], confidence }`
- [ ] Integra√ß√£o em `geminiService.ts`

### Sistema RAG
- [ ] M√∫ltiplas queries paralelas implementadas (6-9 queries)
- [ ] Query espec√≠fica de IA adicionada quando detectado
- [ ] Filtro por contexto de sistema funcionando
- [ ] Deduplica√ß√£o por chunk espec√≠fico
- [ ] Deduplica√ß√£o por vers√£o mais recente
- [ ] Prioriza√ß√£o de documentos-chave (Kickoff, Arquitetura)
- [ ] Score threshold din√¢mico (0.55 key docs, 0.65 outros)

### Knowledge Base
- [ ] `knowledge-base/` criada
- [ ] `OWASP-LLM-Top-10.md` presente
- [ ] `AI-TRiSM-Framework.md` presente
- [ ] `AI-Regulations-Compliance.md` presente
- [ ] `AI-Blind-Spots-Challenges.md` presente
- [ ] `NIST-AI-RMF.md` CRIADO ‚≠ê
- [ ] Documentos carregados no Neo4j
- [ ] CAPEC-STRIDE mapping presente

### Integra√ß√£o DFD
- [ ] `diagramConverter.ts` analisa todos os fluxos
- [ ] Detec√ß√£o de fluxos n√£o criptografados
- [ ] Detec√ß√£o de dados sens√≠veis
- [ ] Detec√ß√£o de cross-boundary flows
- [ ] Contexto rico enviado em `additionalContext`
- [ ] IA recebe an√°lise completa do DFD

### Testes
- [ ] Testar sistema COM IA (deve adicionar query OWASP LLM)
- [ ] Testar sistema SEM IA (n√£o deve adicionar query)
- [ ] Testar fluxo n√£o criptografado (deve gerar alerta CRITICAL)
- [ ] Testar m√∫ltiplas vers√µes do mesmo doc (deve manter mais recente)
- [ ] Testar documento-chave (deve priorizar)
- [ ] Verificar logs do RAG (deve mostrar documentos inclu√≠dos)

---

## üéØ Conclus√£o

Este sistema implementa um **threat modeling inteligente** que:

‚úÖ **Detecta automaticamente** componentes de IA com 3 n√≠veis de confian√ßa  
‚úÖ **Busca conhecimento espec√≠fico** (OWASP LLM, TRiSM, NIST RMF) quando IA √© detectada  
‚úÖ **Analisa TODOS os componentes do DFD** incluindo fluxos, criptografia e boundaries  
‚úÖ **Prioriza documentos-chave** e mant√©m apenas vers√µes mais recentes  
‚úÖ **Deduplica de forma inteligente** (por chunk + por vers√£o)  
‚úÖ **Integra knowledge base rica** com 5+ documentos especializados  
‚úÖ **Gera an√°lises completas** considerando STRIDE + OWASP LLM + TRiSM + NIST RMF  

---

**Vers√£o**: 2.0  
**Data**: Outubro 2025  
**Autor**: Threat Modeling Co-Pilot with AI  
**Licen√ßa**: Propriet√°ria  
**Documento Relacionado**: `VISUAL-EDITOR-IMPLEMENTATION-GUIDE.md`

---

**üöÄ Sistema 100% Pronto para Produ√ß√£o!**

Qualquer agente IA pode ler este documento e implementar todas as funcionalidades em outro sistema seguindo as instru√ß√µes passo a passo.